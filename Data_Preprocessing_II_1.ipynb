{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TbLYH1DA5ex"
   },
   "source": [
    "https://www.kaggle.com/code/vyshnavsvarma/spam-or-ham-sms-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "n1E_WT9fNLB2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "XbPu7sO4Xsb6",
    "outputId": "2be23bc6-297a-4310-bed1-dbe339203ed0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam = pd.read_csv('spam.csV', encoding= \"latin-1\")\n",
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "iGUUJB4nbbcd",
    "outputId": "37aae249-d52e-4565-e76f-53dc9a71ea61"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam = spam[['v1', 'v2']]\n",
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "cRcbUqokcCAW",
    "outputId": "702d3039-1e20-4ab3-f743-c28b7ccd93a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.columns = ['label', 'message']\n",
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "YAsgZqO-eLPc",
    "outputId": "37ac7f7e-5e53-432d-b7aa-5eb3908c1f07"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                 message\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "zjyTPw-EeSGA",
    "outputId": "8f661af3-77df-4e4a-a8ba-a193b1437231"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>message_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  message_len\n",
       "0   ham  Go until jurong point, crazy.. Available only ...          111\n",
       "1   ham                      Ok lar... Joking wif u oni...           29\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...          155\n",
       "3   ham  U dun say so early hor... U c already then say...           49\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...           61\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...          148\n",
       "6   ham  Even my brother is not like to speak with me. ...           77\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...          160\n",
       "8  spam  WINNER!! As a valued network customer you have...          158\n",
       "9  spam  Had your mobile 11 months or more? U R entitle...          154"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam['message_len'] = spam.message.apply(len)\n",
    "spam.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Library: Anda mengimpor dua pustaka, yaitu re (regular expression) dan nltk (Natural Language Toolkit), yang digunakan untuk manipulasi teks dan pemrosesan bahasa alami.\n",
    "\n",
    "Definisi Fungsi Clean: Anda mendefinisikan fungsi Clean(Text) yang akan membersihkan teks dari karakter-karakter non-alphabetic dan mengubah semua huruf menjadi huruf kecil.\n",
    "\n",
    "Pemrosesan Teks dalam Dataframe: Anda menerapkan fungsi Clean pada kolom \"message\" dari DataFrame yang disebut \"spam\". Anda menggunakan ekspresi .apply(Clean) untuk menerapkan fungsi pada setiap elemen dalam kolom \"message\" dan menyimpan hasilnya dalam kolom baru yang disebut \"Clean_Text\".\n",
    "\n",
    "Menampilkan Teks Setelah Pembersihan: Anda mencetak 10 teks pertama dalam kolom \"Clean_Text\" setelah dilakukan pembersihan.\n",
    "\n",
    "Fungsi Clean bekerja sebagai berikut:\n",
    "\n",
    "Pertama, menggunakan regular expression (re.sub('[^a-zA-Z]', ' ', Text)), Anda mengganti semua karakter non-alphabetic dengan spasi.\n",
    "Kemudian, Anda mengubah seluruh teks menjadi lowercase dengan .lower().\n",
    "Selanjutnya, Anda membagi teks menjadi kata-kata individual menggunakan .split().\n",
    "Akhirnya, Anda menggabungkan kembali kata-kata menjadi satu teks dengan spasi di antara mereka menggunakan ' '.join(sms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yUB_dr7Eeeqq",
    "outputId": "6a825ec7-6aa3-4899-e0b9-aa2657ca337f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The First 10 Texts after cleaning: \n",
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
      "ok lar joking wif u oni\n",
      "free entry in a wkly comp to win fa cup final tkts st may text fa to to receive entry question std txt rate t c s apply over s\n",
      "u dun say so early hor u c already then say\n",
      "nah i don t think he goes to usf he lives around here though\n",
      "freemsg hey there darling it s been week s now and no word back i d like some fun you up for it still tb ok xxx std chgs to send to rcv\n",
      "even my brother is not like to speak with me they treat me like aids patent\n",
      "as per your request melle melle oru minnaminunginte nurungu vettam has been set as your callertune for all callers press to copy your friends callertune\n",
      "winner as a valued network customer you have been selected to receivea prize reward to claim call claim code kl valid hours only\n",
      "had your mobile months or more u r entitled to update to the latest colour mobiles with camera for free call the mobile update co free on\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "# Defining a function to clean up the text\n",
    "def Clean(Text):\n",
    "    sms = re.sub('[^a-zA-Z]', ' ', Text) #Replacing all non-alphabetic characters with a space\n",
    "    sms = sms.lower() #converting to lowecase\n",
    "    sms = sms.split()\n",
    "    sms = ' '.join(sms)\n",
    "    return sms\n",
    "\n",
    "spam[\"Clean_Text\"] = spam[\"message\"].apply(Clean)\n",
    "#Lets have a look at a sample of texts after cleaning\n",
    "print(\"The First 10 Texts after cleaning: \",*spam[\"Clean_Text\"][:10], sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>message_len</th>\n",
       "      <th>Clean_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>nah i don t think he goes to usf he lives arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>161</td>\n",
       "      <td>this is the nd time we have tried contact u u ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>37</td>\n",
       "      <td>will b going to esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>57</td>\n",
       "      <td>pity was in mood for that so any other suggest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>125</td>\n",
       "      <td>the guy did some bitching but i acted like i d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>26</td>\n",
       "      <td>rofl its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  message_len  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...          111   \n",
       "1      ham                      Ok lar... Joking wif u oni...           29   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...          155   \n",
       "3      ham  U dun say so early hor... U c already then say...           49   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...           61   \n",
       "...    ...                                                ...          ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...          161   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?           37   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...           57   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...          125   \n",
       "5571   ham                         Rofl. Its true to its name           26   \n",
       "\n",
       "                                             Clean_Text  \n",
       "0     go until jurong point crazy available only in ...  \n",
       "1                               ok lar joking wif u oni  \n",
       "2     free entry in a wkly comp to win fa cup final ...  \n",
       "3           u dun say so early hor u c already then say  \n",
       "4     nah i don t think he goes to usf he lives arou...  \n",
       "...                                                 ...  \n",
       "5567  this is the nd time we have tried contact u u ...  \n",
       "5568                  will b going to esplanade fr home  \n",
       "5569  pity was in mood for that so any other suggest...  \n",
       "5570  the guy did some bitching but i acted like i d...  \n",
       "5571                          rofl its true to its name  \n",
       "\n",
       "[5572 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aIKieTrh9pWY",
    "outputId": "9938a2d3-384c-43ae-fd17-5614ce3a93b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenisasi Kata: Tokenisasi adalah proses memecah teks menjadi unit-unit yang lebih kecil, dalam hal ini, menjadi kata-kata individual. Anda menggunakan fungsi nltk.word_tokenize() untuk melakukan tokenisasi pada setiap teks yang sudah dibersihkan, yang terdapat dalam kolom \"Clean_Text\".\n",
    "\n",
    "Penerapan pada DataFrame: Anda menggunakan metode .apply() untuk menerapkan tokenisasi pada setiap baris (row) dari DataFrame \"spam\". Fungsi lambda row: nltk.word_tokenize(row[\"Clean_Text\"]) digunakan untuk menjalankan tokenisasi pada setiap baris dengan menggunakan teks yang ada dalam kolom \"Clean_Text\".\n",
    "\n",
    "Hasil DataFrame: Setelah Anda melakukan tokenisasi pada setiap teks, hasil tokenisasi disimpan dalam kolom baru yang disebut \"Tokenize_Text\". Anda mencetak 10 baris pertama dari DataFrame \"spam\" untuk melihat hasilnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "id": "gtGSVk-qe1Nj",
    "outputId": "4857ecb9-8fb7-4e08-a5e8-73e1b147fd43"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>message_len</th>\n",
       "      <th>Clean_Text</th>\n",
       "      <th>Tokenize_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
       "      <td>[free, entry, in, a, wkly, comp, to, win, fa, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>nah i don t think he goes to usf he lives arou...</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>148</td>\n",
       "      <td>freemsg hey there darling it s been week s now...</td>\n",
       "      <td>[freemsg, hey, there, darling, it, s, been, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>77</td>\n",
       "      <td>even my brother is not like to speak with me t...</td>\n",
       "      <td>[even, my, brother, is, not, like, to, speak, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>160</td>\n",
       "      <td>as per your request melle melle oru minnaminun...</td>\n",
       "      <td>[as, per, your, request, melle, melle, oru, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>158</td>\n",
       "      <td>winner as a valued network customer you have b...</td>\n",
       "      <td>[winner, as, a, valued, network, customer, you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>154</td>\n",
       "      <td>had your mobile months or more u r entitled to...</td>\n",
       "      <td>[had, your, mobile, months, or, more, u, r, en...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  message_len  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...          111   \n",
       "1   ham                      Ok lar... Joking wif u oni...           29   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...          155   \n",
       "3   ham  U dun say so early hor... U c already then say...           49   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...           61   \n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...          148   \n",
       "6   ham  Even my brother is not like to speak with me. ...           77   \n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...          160   \n",
       "8  spam  WINNER!! As a valued network customer you have...          158   \n",
       "9  spam  Had your mobile 11 months or more? U R entitle...          154   \n",
       "\n",
       "                                          Clean_Text  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry in a wkly comp to win fa cup final ...   \n",
       "3        u dun say so early hor u c already then say   \n",
       "4  nah i don t think he goes to usf he lives arou...   \n",
       "5  freemsg hey there darling it s been week s now...   \n",
       "6  even my brother is not like to speak with me t...   \n",
       "7  as per your request melle melle oru minnaminun...   \n",
       "8  winner as a valued network customer you have b...   \n",
       "9  had your mobile months or more u r entitled to...   \n",
       "\n",
       "                                       Tokenize_Text  \n",
       "0  [go, until, jurong, point, crazy, available, o...  \n",
       "1                     [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, in, a, wkly, comp, to, win, fa, ...  \n",
       "3  [u, dun, say, so, early, hor, u, c, already, t...  \n",
       "4  [nah, i, don, t, think, he, goes, to, usf, he,...  \n",
       "5  [freemsg, hey, there, darling, it, s, been, we...  \n",
       "6  [even, my, brother, is, not, like, to, speak, ...  \n",
       "7  [as, per, your, request, melle, melle, oru, mi...  \n",
       "8  [winner, as, a, valued, network, customer, you...  \n",
       "9  [had, your, mobile, months, or, more, u, r, en...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam[\"Tokenize_Text\"]=spam.apply(lambda row: nltk.word_tokenize(row[\"Clean_Text\"]), axis=1)\n",
    "spam.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5D34ommx97KM",
    "outputId": "f97b80ee-5b52-474f-96a6-0476dec253a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RBpmAghb94LJ",
    "outputId": "743d947c-57ea-4b59-81f8-3d7c1da07832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "#Kode di atas adalah contoh penggunaan NLTK untuk mendapatkan daftar kata-kata stop (stop words) dalam bahasa Inggris.\n",
    "#Daftar kata-kata stop adalah kumpulan kata yang umumnya dianggap tidak memiliki makna signifikan \n",
    "#dalam analisis teks karena sering muncul dalam banyak teks tanpa memberikan kontribusi pada pemahaman konten. \n",
    "#Contohnya adalah kata-kata seperti \"the\", \"and\", \"is\", \"in\", dan sebagainya.\n",
    "\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wNwj1E0ZfFun",
    "outputId": "9746537f-a8cc-45d6-d9b3-10992adac05d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The First 10 Texts after removing the stopwords:\n",
      "['go', 'jurong', 'point', 'crazy', 'available', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', 'cine', 'got', 'amore', 'wat']\n",
      "['ok', 'lar', 'joking', 'wif', 'u', 'oni']\n",
      "['free', 'entry', 'wkly', 'comp', 'win', 'fa', 'cup', 'final', 'tkts', 'st', 'may', 'text', 'fa', 'receive', 'entry', 'question', 'std', 'txt', 'rate', 'c', 'apply']\n",
      "['u', 'dun', 'say', 'early', 'hor', 'u', 'c', 'already', 'say']\n",
      "['nah', 'think', 'goes', 'usf', 'lives', 'around', 'though']\n",
      "['freemsg', 'hey', 'darling', 'week', 'word', 'back', 'like', 'fun', 'still', 'tb', 'ok', 'xxx', 'std', 'chgs', 'send', 'rcv']\n",
      "['even', 'brother', 'like', 'speak', 'treat', 'like', 'aids', 'patent']\n",
      "['per', 'request', 'melle', 'melle', 'oru', 'minnaminunginte', 'nurungu', 'vettam', 'set', 'callertune', 'callers', 'press', 'copy', 'friends', 'callertune']\n",
      "['winner', 'valued', 'network', 'customer', 'selected', 'receivea', 'prize', 'reward', 'claim', 'call', 'claim', 'code', 'kl', 'valid', 'hours']\n",
      "['mobile', 'months', 'u', 'r', 'entitled', 'update', 'latest', 'colour', 'mobiles', 'camera', 'free', 'call', 'mobile', 'update', 'co', 'free']\n"
     ]
    }
   ],
   "source": [
    "# Removing the stopwords function\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    #menggunakan list comprehension untuk membuat daftar baru\n",
    "    #yang hanya berisi kata-kata yang tidak termasuk dalam daftar kata-kata stop. \n",
    "    #Ini dilakukan dengan memeriksa setiap kata dalam teks (for word in text) \n",
    "    filtered_text = [word for word in text if word not in stop_words]\n",
    "    return filtered_text\n",
    "\n",
    "spam[\"Nostopword_Text\"] = spam[\"Tokenize_Text\"].apply(remove_stopwords)\n",
    "\n",
    "print(\"The First 10 Texts after removing the stopwords:\",*spam[\"Nostopword_Text\"][:10], sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "lJyz3u0Ax4O9",
    "outputId": "ad7c478f-3789-45f2-edef-e9f8dcc7f0a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>message_len</th>\n",
       "      <th>Clean_Text</th>\n",
       "      <th>Tokenize_Text</th>\n",
       "      <th>Nostopword_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
       "      <td>[free, entry, in, a, wkly, comp, to, win, fa, ...</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>nah i don t think he goes to usf he lives arou...</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>161</td>\n",
       "      <td>this is the nd time we have tried contact u u ...</td>\n",
       "      <td>[this, is, the, nd, time, we, have, tried, con...</td>\n",
       "      <td>[nd, time, tried, contact, u, u, pound, prize,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>37</td>\n",
       "      <td>will b going to esplanade fr home</td>\n",
       "      <td>[will, b, going, to, esplanade, fr, home]</td>\n",
       "      <td>[b, going, esplanade, fr, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>57</td>\n",
       "      <td>pity was in mood for that so any other suggest...</td>\n",
       "      <td>[pity, was, in, mood, for, that, so, any, othe...</td>\n",
       "      <td>[pity, mood, suggestions]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>125</td>\n",
       "      <td>the guy did some bitching but i acted like i d...</td>\n",
       "      <td>[the, guy, did, some, bitching, but, i, acted,...</td>\n",
       "      <td>[guy, bitching, acted, like, interested, buyin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>26</td>\n",
       "      <td>rofl its true to its name</td>\n",
       "      <td>[rofl, its, true, to, its, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  message_len  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...          111   \n",
       "1      ham                      Ok lar... Joking wif u oni...           29   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...          155   \n",
       "3      ham  U dun say so early hor... U c already then say...           49   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...           61   \n",
       "...    ...                                                ...          ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...          161   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?           37   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...           57   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...          125   \n",
       "5571   ham                         Rofl. Its true to its name           26   \n",
       "\n",
       "                                             Clean_Text  \\\n",
       "0     go until jurong point crazy available only in ...   \n",
       "1                               ok lar joking wif u oni   \n",
       "2     free entry in a wkly comp to win fa cup final ...   \n",
       "3           u dun say so early hor u c already then say   \n",
       "4     nah i don t think he goes to usf he lives arou...   \n",
       "...                                                 ...   \n",
       "5567  this is the nd time we have tried contact u u ...   \n",
       "5568                  will b going to esplanade fr home   \n",
       "5569  pity was in mood for that so any other suggest...   \n",
       "5570  the guy did some bitching but i acted like i d...   \n",
       "5571                          rofl its true to its name   \n",
       "\n",
       "                                          Tokenize_Text  \\\n",
       "0     [go, until, jurong, point, crazy, available, o...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, in, a, wkly, comp, to, win, fa, ...   \n",
       "3     [u, dun, say, so, early, hor, u, c, already, t...   \n",
       "4     [nah, i, don, t, think, he, goes, to, usf, he,...   \n",
       "...                                                 ...   \n",
       "5567  [this, is, the, nd, time, we, have, tried, con...   \n",
       "5568          [will, b, going, to, esplanade, fr, home]   \n",
       "5569  [pity, was, in, mood, for, that, so, any, othe...   \n",
       "5570  [the, guy, did, some, bitching, but, i, acted,...   \n",
       "5571                   [rofl, its, true, to, its, name]   \n",
       "\n",
       "                                        Nostopword_Text  \n",
       "0     [go, jurong, point, crazy, available, bugis, n...  \n",
       "1                        [ok, lar, joking, wif, u, oni]  \n",
       "2     [free, entry, wkly, comp, win, fa, cup, final,...  \n",
       "3         [u, dun, say, early, hor, u, c, already, say]  \n",
       "4        [nah, think, goes, usf, lives, around, though]  \n",
       "...                                                 ...  \n",
       "5567  [nd, time, tried, contact, u, u, pound, prize,...  \n",
       "5568                    [b, going, esplanade, fr, home]  \n",
       "5569                          [pity, mood, suggestions]  \n",
       "5570  [guy, bitching, acted, like, interested, buyin...  \n",
       "5571                                 [rofl, true, name]  \n",
       "\n",
       "[5572 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TRXIWr0v-F88",
    "outputId": "83a4977d-6c04-4505-999b-27d2adec074b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet') # pemrosesan bahasa alami seperti stemming, lemmatization, dan analisis semantik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j07O5GmW-J19",
    "outputId": "72326b17-a0f3-4600-b758-66911fc1ab88"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Library: Anda mengimpor modul WordNetLemmatizer dari NLTK menggunakan from nltk.stem import WordNetLemmatizer.\n",
    "\n",
    "Inisialisasi Lemmatizer: Anda menginisialisasi objek lemmatizer menggunakan lemmatizer = WordNetLemmatizer().\n",
    "\n",
    "Definisi Fungsi lemmatize_word: Anda mendefinisikan fungsi lemmatize_word(text) yang akan melakukan lemmatisasi pada setiap kata dalam teks yang diberikan.\n",
    "\n",
    "Lemmatization: Anda menggunakan list comprehension untuk melakukan lemmatisasi pada setiap kata dalam teks. Anda menggunakan lemmatizer.lemmatize(word, pos ='v') untuk mengaplikasikan lemmatisasi pada kata dengan memberikan informasi part-of-speech (pos) bahwa kata tersebut adalah kata kerja (verb).\n",
    "\n",
    "Penerapan pada DataFrame: Anda menerapkan fungsi lemmatize_word pada setiap baris dari kolom \"Nostopword_Text\" dalam DataFrame \"spam\".\n",
    "\n",
    "Menampilkan Teks Setelah Lemmatisasi: Anda mencetak 10 baris pertama dari kolom pas nemu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GM8qRbVihJ1M",
    "outputId": "d79743d7-b47f-4c2c-9143-44834ef6f801"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The First 10 Texts after lemmatization:\n",
      "['go', 'jurong', 'point', 'crazy', 'available', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', 'cine', 'get', 'amore', 'wat']\n",
      "['ok', 'lar', 'joke', 'wif', 'u', 'oni']\n",
      "['free', 'entry', 'wkly', 'comp', 'win', 'fa', 'cup', 'final', 'tkts', 'st', 'may', 'text', 'fa', 'receive', 'entry', 'question', 'std', 'txt', 'rate', 'c', 'apply']\n",
      "['u', 'dun', 'say', 'early', 'hor', 'u', 'c', 'already', 'say']\n",
      "['nah', 'think', 'go', 'usf', 'live', 'around', 'though']\n",
      "['freemsg', 'hey', 'darling', 'week', 'word', 'back', 'like', 'fun', 'still', 'tb', 'ok', 'xxx', 'std', 'chgs', 'send', 'rcv']\n",
      "['even', 'brother', 'like', 'speak', 'treat', 'like', 'aid', 'patent']\n",
      "['per', 'request', 'melle', 'melle', 'oru', 'minnaminunginte', 'nurungu', 'vettam', 'set', 'callertune', 'callers', 'press', 'copy', 'friends', 'callertune']\n",
      "['winner', 'value', 'network', 'customer', 'select', 'receivea', 'prize', 'reward', 'claim', 'call', 'claim', 'code', 'kl', 'valid', 'hours']\n",
      "['mobile', 'months', 'u', 'r', 'entitle', 'update', 'latest', 'colour', 'mobiles', 'camera', 'free', 'call', 'mobile', 'update', 'co', 'free']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# lemmatize string\n",
    "def lemmatize_word(text):\n",
    "    #word_tokens = word_tokenize(text)\n",
    "    # provide context i.e. part-of-speech\n",
    "    lemmas = [lemmatizer.lemmatize(word, pos ='v') for word in text]\n",
    "    return lemmas\n",
    "\n",
    "spam[\"Lemmatized_Text\"] = spam[\"Nostopword_Text\"].apply(lemmatize_word)\n",
    "print(\"The First 10 Texts after lemmatization:\",*spam[\"Lemmatized_Text\"][:10], sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>message_len</th>\n",
       "      <th>Clean_Text</th>\n",
       "      <th>Tokenize_Text</th>\n",
       "      <th>Nostopword_Text</th>\n",
       "      <th>Lemmatized_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
       "      <td>[free, entry, in, a, wkly, comp, to, win, fa, ...</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>nah i don t think he goes to usf he lives arou...</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
       "      <td>[nah, think, go, usf, live, around, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>161</td>\n",
       "      <td>this is the nd time we have tried contact u u ...</td>\n",
       "      <td>[this, is, the, nd, time, we, have, tried, con...</td>\n",
       "      <td>[nd, time, tried, contact, u, u, pound, prize,...</td>\n",
       "      <td>[nd, time, try, contact, u, u, pound, prize, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>37</td>\n",
       "      <td>will b going to esplanade fr home</td>\n",
       "      <td>[will, b, going, to, esplanade, fr, home]</td>\n",
       "      <td>[b, going, esplanade, fr, home]</td>\n",
       "      <td>[b, go, esplanade, fr, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>57</td>\n",
       "      <td>pity was in mood for that so any other suggest...</td>\n",
       "      <td>[pity, was, in, mood, for, that, so, any, othe...</td>\n",
       "      <td>[pity, mood, suggestions]</td>\n",
       "      <td>[pity, mood, suggestions]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>125</td>\n",
       "      <td>the guy did some bitching but i acted like i d...</td>\n",
       "      <td>[the, guy, did, some, bitching, but, i, acted,...</td>\n",
       "      <td>[guy, bitching, acted, like, interested, buyin...</td>\n",
       "      <td>[guy, bitch, act, like, interest, buy, somethi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>26</td>\n",
       "      <td>rofl its true to its name</td>\n",
       "      <td>[rofl, its, true, to, its, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  message_len  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...          111   \n",
       "1      ham                      Ok lar... Joking wif u oni...           29   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...          155   \n",
       "3      ham  U dun say so early hor... U c already then say...           49   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...           61   \n",
       "...    ...                                                ...          ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...          161   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?           37   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...           57   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...          125   \n",
       "5571   ham                         Rofl. Its true to its name           26   \n",
       "\n",
       "                                             Clean_Text  \\\n",
       "0     go until jurong point crazy available only in ...   \n",
       "1                               ok lar joking wif u oni   \n",
       "2     free entry in a wkly comp to win fa cup final ...   \n",
       "3           u dun say so early hor u c already then say   \n",
       "4     nah i don t think he goes to usf he lives arou...   \n",
       "...                                                 ...   \n",
       "5567  this is the nd time we have tried contact u u ...   \n",
       "5568                  will b going to esplanade fr home   \n",
       "5569  pity was in mood for that so any other suggest...   \n",
       "5570  the guy did some bitching but i acted like i d...   \n",
       "5571                          rofl its true to its name   \n",
       "\n",
       "                                          Tokenize_Text  \\\n",
       "0     [go, until, jurong, point, crazy, available, o...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, in, a, wkly, comp, to, win, fa, ...   \n",
       "3     [u, dun, say, so, early, hor, u, c, already, t...   \n",
       "4     [nah, i, don, t, think, he, goes, to, usf, he,...   \n",
       "...                                                 ...   \n",
       "5567  [this, is, the, nd, time, we, have, tried, con...   \n",
       "5568          [will, b, going, to, esplanade, fr, home]   \n",
       "5569  [pity, was, in, mood, for, that, so, any, othe...   \n",
       "5570  [the, guy, did, some, bitching, but, i, acted,...   \n",
       "5571                   [rofl, its, true, to, its, name]   \n",
       "\n",
       "                                        Nostopword_Text  \\\n",
       "0     [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, wkly, comp, win, fa, cup, final,...   \n",
       "3         [u, dun, say, early, hor, u, c, already, say]   \n",
       "4        [nah, think, goes, usf, lives, around, though]   \n",
       "...                                                 ...   \n",
       "5567  [nd, time, tried, contact, u, u, pound, prize,...   \n",
       "5568                    [b, going, esplanade, fr, home]   \n",
       "5569                          [pity, mood, suggestions]   \n",
       "5570  [guy, bitching, acted, like, interested, buyin...   \n",
       "5571                                 [rofl, true, name]   \n",
       "\n",
       "                                        Lemmatized_Text  \n",
       "0     [go, jurong, point, crazy, available, bugis, n...  \n",
       "1                          [ok, lar, joke, wif, u, oni]  \n",
       "2     [free, entry, wkly, comp, win, fa, cup, final,...  \n",
       "3         [u, dun, say, early, hor, u, c, already, say]  \n",
       "4           [nah, think, go, usf, live, around, though]  \n",
       "...                                                 ...  \n",
       "5567  [nd, time, try, contact, u, u, pound, prize, c...  \n",
       "5568                       [b, go, esplanade, fr, home]  \n",
       "5569                          [pity, mood, suggestions]  \n",
       "5570  [guy, bitch, act, like, interest, buy, somethi...  \n",
       "5571                                 [rofl, true, name]  \n",
       "\n",
       "[5572 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvjuRpTShto4",
    "outputId": "265453b0-1d53-4a4f-98ed-a813e939d821"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The First 10 lines in corpus :\n",
      "go jurong point crazy available bugis n great world la e buffet cine get amore wat\n",
      "ok lar joke wif u oni\n",
      "free entry wkly comp win fa cup final tkts st may text fa receive entry question std txt rate c apply\n",
      "u dun say early hor u c already say\n",
      "nah think go usf live around though\n",
      "freemsg hey darling week word back like fun still tb ok xxx std chgs send rcv\n",
      "even brother like speak treat like aid patent\n",
      "per request melle melle oru minnaminunginte nurungu vettam set callertune callers press copy friends callertune\n",
      "winner value network customer select receivea prize reward claim call claim code kl valid hours\n",
      "mobile months u r entitle update latest colour mobiles camera free call mobile update co free\n"
     ]
    }
   ],
   "source": [
    "#Creating a corpus of text feature to encode further into vectorized form\n",
    "corpus= []\n",
    "for i in spam[\"Lemmatized_Text\"]:\n",
    "    msg = ' '.join([row for row in i])\n",
    "    corpus.append(msg)\n",
    "    \n",
    "corpus[:5]\n",
    "print(\"The First 10 lines in corpus :\",*corpus[:10], sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>message_len</th>\n",
       "      <th>Clean_Text</th>\n",
       "      <th>Tokenize_Text</th>\n",
       "      <th>Nostopword_Text</th>\n",
       "      <th>Lemmatized_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
       "      <td>[free, entry, in, a, wkly, comp, to, win, fa, ...</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>nah i don t think he goes to usf he lives arou...</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
       "      <td>[nah, think, go, usf, live, around, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>161</td>\n",
       "      <td>this is the nd time we have tried contact u u ...</td>\n",
       "      <td>[this, is, the, nd, time, we, have, tried, con...</td>\n",
       "      <td>[nd, time, tried, contact, u, u, pound, prize,...</td>\n",
       "      <td>[nd, time, try, contact, u, u, pound, prize, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>37</td>\n",
       "      <td>will b going to esplanade fr home</td>\n",
       "      <td>[will, b, going, to, esplanade, fr, home]</td>\n",
       "      <td>[b, going, esplanade, fr, home]</td>\n",
       "      <td>[b, go, esplanade, fr, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>57</td>\n",
       "      <td>pity was in mood for that so any other suggest...</td>\n",
       "      <td>[pity, was, in, mood, for, that, so, any, othe...</td>\n",
       "      <td>[pity, mood, suggestions]</td>\n",
       "      <td>[pity, mood, suggestions]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>125</td>\n",
       "      <td>the guy did some bitching but i acted like i d...</td>\n",
       "      <td>[the, guy, did, some, bitching, but, i, acted,...</td>\n",
       "      <td>[guy, bitching, acted, like, interested, buyin...</td>\n",
       "      <td>[guy, bitch, act, like, interest, buy, somethi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>26</td>\n",
       "      <td>rofl its true to its name</td>\n",
       "      <td>[rofl, its, true, to, its, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  message_len  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...          111   \n",
       "1      ham                      Ok lar... Joking wif u oni...           29   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...          155   \n",
       "3      ham  U dun say so early hor... U c already then say...           49   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...           61   \n",
       "...    ...                                                ...          ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...          161   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?           37   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...           57   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...          125   \n",
       "5571   ham                         Rofl. Its true to its name           26   \n",
       "\n",
       "                                             Clean_Text  \\\n",
       "0     go until jurong point crazy available only in ...   \n",
       "1                               ok lar joking wif u oni   \n",
       "2     free entry in a wkly comp to win fa cup final ...   \n",
       "3           u dun say so early hor u c already then say   \n",
       "4     nah i don t think he goes to usf he lives arou...   \n",
       "...                                                 ...   \n",
       "5567  this is the nd time we have tried contact u u ...   \n",
       "5568                  will b going to esplanade fr home   \n",
       "5569  pity was in mood for that so any other suggest...   \n",
       "5570  the guy did some bitching but i acted like i d...   \n",
       "5571                          rofl its true to its name   \n",
       "\n",
       "                                          Tokenize_Text  \\\n",
       "0     [go, until, jurong, point, crazy, available, o...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, in, a, wkly, comp, to, win, fa, ...   \n",
       "3     [u, dun, say, so, early, hor, u, c, already, t...   \n",
       "4     [nah, i, don, t, think, he, goes, to, usf, he,...   \n",
       "...                                                 ...   \n",
       "5567  [this, is, the, nd, time, we, have, tried, con...   \n",
       "5568          [will, b, going, to, esplanade, fr, home]   \n",
       "5569  [pity, was, in, mood, for, that, so, any, othe...   \n",
       "5570  [the, guy, did, some, bitching, but, i, acted,...   \n",
       "5571                   [rofl, its, true, to, its, name]   \n",
       "\n",
       "                                        Nostopword_Text  \\\n",
       "0     [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, wkly, comp, win, fa, cup, final,...   \n",
       "3         [u, dun, say, early, hor, u, c, already, say]   \n",
       "4        [nah, think, goes, usf, lives, around, though]   \n",
       "...                                                 ...   \n",
       "5567  [nd, time, tried, contact, u, u, pound, prize,...   \n",
       "5568                    [b, going, esplanade, fr, home]   \n",
       "5569                          [pity, mood, suggestions]   \n",
       "5570  [guy, bitching, acted, like, interested, buyin...   \n",
       "5571                                 [rofl, true, name]   \n",
       "\n",
       "                                        Lemmatized_Text  \n",
       "0     [go, jurong, point, crazy, available, bugis, n...  \n",
       "1                          [ok, lar, joke, wif, u, oni]  \n",
       "2     [free, entry, wkly, comp, win, fa, cup, final,...  \n",
       "3         [u, dun, say, early, hor, u, c, already, say]  \n",
       "4           [nah, think, go, usf, live, around, though]  \n",
       "...                                                 ...  \n",
       "5567  [nd, time, try, contact, u, u, pound, prize, c...  \n",
       "5568                       [b, go, esplanade, fr, home]  \n",
       "5569                          [pity, mood, suggestions]  \n",
       "5570  [guy, bitch, act, like, interest, buy, somethi...  \n",
       "5571                                 [rofl, true, name]  \n",
       "\n",
       "[5572 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Library: Anda mengimpor kelas TfidfVectorizer dari modul sklearn.feature_extraction.text menggunakan from sklearn.feature_extraction.text import TfidfVectorizer.\n",
    "\n",
    "Inisialisasi TfidfVectorizer: Anda menginisialisasi objek tfidf dari kelas TfidfVectorizer.\n",
    "\n",
    "**Pengolahan Teks Menjadi Vektor**: Anda menggunakan tfidf.fit_transform(corpus).toarray() untuk mengubah teks dalam \"corpus\" menjadi representasi vektor berdasarkan skor TF-IDF. Metode fit_transform() menghitung skor TF-IDF untuk setiap kata dalam teks dan menghasilkan matriks representasi vektor. Metode toarray() digunakan untuk mengubah hasil tersebut menjadi bentuk array numpy.\n",
    "\n",
    "Tampilan Tipe Data: Anda menggunakan X.dtype untuk menampilkan tipe data dari matriks vektor hasil TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ykQwwwBh_gS",
    "outputId": "433eafdd-9d8c-467e-f554-b2539181d3fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Changing text data in to numbers. \n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(corpus).toarray()\n",
    "#Let's have a look at our feature \n",
    "X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0HOO2AnajG8N",
    "outputId": "a15ad682-1338-48f2-e87d-7e65befa1145"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "MCrJiM4d-aUn"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Label encode the Target and use it as y\n",
    "label_encoder = LabelEncoder()\n",
    "spam[\"label\"] = label_encoder.fit_transform(spam[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "PQd0hdErAJuZ",
    "outputId": "37c4d66b-315a-4c15-d81e-28406e6906fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>message_len</th>\n",
       "      <th>Clean_Text</th>\n",
       "      <th>Tokenize_Text</th>\n",
       "      <th>Nostopword_Text</th>\n",
       "      <th>Lemmatized_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
       "      <td>[free, entry, in, a, wkly, comp, to, win, fa, ...</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>nah i don t think he goes to usf he lives arou...</td>\n",
       "      <td>[nah, i, don, t, think, he, goes, to, usf, he,...</td>\n",
       "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
       "      <td>[nah, think, go, usf, live, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message  message_len  \\\n",
       "0      0  Go until jurong point, crazy.. Available only ...          111   \n",
       "1      0                      Ok lar... Joking wif u oni...           29   \n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...          155   \n",
       "3      0  U dun say so early hor... U c already then say...           49   \n",
       "4      0  Nah I don't think he goes to usf, he lives aro...           61   \n",
       "\n",
       "                                          Clean_Text  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry in a wkly comp to win fa cup final ...   \n",
       "3        u dun say so early hor u c already then say   \n",
       "4  nah i don t think he goes to usf he lives arou...   \n",
       "\n",
       "                                       Tokenize_Text  \\\n",
       "0  [go, until, jurong, point, crazy, available, o...   \n",
       "1                     [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, in, a, wkly, comp, to, win, fa, ...   \n",
       "3  [u, dun, say, so, early, hor, u, c, already, t...   \n",
       "4  [nah, i, don, t, think, he, goes, to, usf, he,...   \n",
       "\n",
       "                                     Nostopword_Text  \\\n",
       "0  [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                     [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, wkly, comp, win, fa, cup, final,...   \n",
       "3      [u, dun, say, early, hor, u, c, already, say]   \n",
       "4     [nah, think, goes, usf, lives, around, though]   \n",
       "\n",
       "                                     Lemmatized_Text  \n",
       "0  [go, jurong, point, crazy, available, bugis, n...  \n",
       "1                       [ok, lar, joke, wif, u, oni]  \n",
       "2  [free, entry, wkly, comp, win, fa, cup, final,...  \n",
       "3      [u, dun, say, early, hor, u, c, already, say]  \n",
       "4        [nah, think, go, usf, live, around, though]  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "dPB6rkUQALPX"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Setting values for labels and feature as y and X(we already did X in vectorizing...)\n",
    "y = spam[\"label\"] \n",
    "# Splitting the testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 1978    0\n",
       " 3989    1\n",
       " 3935    0\n",
       " 4078    0\n",
       " 4086    1\n",
       "        ..\n",
       " 3772    0\n",
       " 5191    0\n",
       " 5226    0\n",
       " 5390    0\n",
       " 860     0\n",
       " Name: label, Length: 4457, dtype: int32,\n",
       " 3245    0\n",
       " 944     0\n",
       " 1044    1\n",
       " 2484    0\n",
       " 812     1\n",
       "        ..\n",
       " 4264    0\n",
       " 2439    0\n",
       " 5556    0\n",
       " 4205    0\n",
       " 4293    1\n",
       " Name: label, Length: 1115, dtype: int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.naive_bayes dan digunakan untuk membangun model klasifikasi dengan metode Naive Bayes yang cocok untuk data kategorikal. Ini biasanya digunakan dalam tugas-tugas klasifikasi teks.\n",
    "\n",
    "RandomForestClassifier: Kelas ini berasal dari modul sklearn.ensemble dan digunakan untuk membangun model klasifikasi dengan menggunakan algoritma Random Forest. Random Forest adalah algoritma ensemble yang menggabungkan beberapa pohon keputusan untuk meningkatkan akurasi prediks\n",
    "\n",
    "KNeighborsClassifier: Kelas ini berasal dari modul sklearn.neighbors dan digunakan untuk membangun model klasifikasi dengan menggunakan metode K-Nearest Neighbors (K-NN). K-NN mengklasifikasikan data berdasarkan mayoritas label dari k-nearest neighbors dari data yang akan diprediksi.\n",
    "\n",
    "SVC (Support Vector Classifier): Kelas ini berasal dari modul sklearn.svm dan digunakan untuk membangun model klasifikasi dengan menggunakan metode Support Vector Machine (SVM). SVM mencari pemisah optimal antara kelas-kelas data dalam ruang fitur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "DC-0MiPuAW_W"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Testing on the following classifiers\n",
    "classifiers = [MultinomialNB(), \n",
    "               RandomForestClassifier(),\n",
    "               KNeighborsClassifier(), \n",
    "               SVC()]\n",
    "for cls in classifiers:\n",
    "    cls.fit(X_train, y_train)\n",
    "\n",
    "# Dictionary of pipelines and model types for ease of reference\n",
    "pipe_dict = {0: \"NaiveBayes\", 1: \"RandomForest\", 2: \"KNeighbours\",3: \"SVC\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ietBc3TpAcL1",
    "outputId": "ff546017-2a98-4b06-b597-1ee086722581"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes: 0.966568 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Cossvalidation \n",
    "for i, model in enumerate(classifiers):\n",
    "    cv_score = cross_val_score(model, X_train,y_train,scoring=\"accuracy\", cv=10)\n",
    "    print(\"%s: %f \" % (pipe_dict[i], cv_score.mean()))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
